---
title: Sorting Algorithms
date: 2018-07-27
draft: false
---

本文的内容是总结数据结构与算法中常见的几种排序算法，算是程序员的基本功之一。首先会从几种简单的排序算法开始，最后会逐渐涉及较为复杂的排序算法。

在本文中，我们首先要约定，我们要排序的元素个数为 N，元素在数组中并且数组以下标 0 开始放置元素。

<!--more-->

## 插入排序
最简单的排序算法实现，在循环的第 N 步，确保前 N 个元素是排序的，相当于每次循环从尾部增加一个元素，并将该元素放置到正确的位置上去。

代码实现：

```c
void InsertionSort(ElementType A[], int N) {
	int j, P;

	ElementType Tmp;
	for (P = 1; P < N; P++) {
		Tmp = A[P];
		for (j = P; j > 0 && A[j - 1] > Tmp; j--)
			A[j] = A[j - 1];
		A[j] = Tmp;
	}
}
```

| 初始 | 34 | 8 | 64 | 51 | 32 | 21 | 移动的次数 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| p=1 后 | 8 | 34 | 64 | 51 | 32 | 21 | 1 |
| p=2 后 | 8 | 34 | 64 | 51 | 32 | 21 | 0 |
| p=3 后 | 8 | 34 | 51 | 64 | 32 | 21 | 1 |
| p=4 后 | 8 | 32 | 34 | 51 | 64 | 21 | 3 |
| p=5 后 | 8 | 21 | 32 | 34 | 51 | 64 | 4 |

这种排序的方式代表了所有的简单排序，包括了选择排序和冒泡排序，它们的时间复杂度可以从代码上显而易见的看出来是 *O(N^2)*。而至于为什么简单排序不能突破 N^2 时间界，有一个很有意思的数学证明。

对于一个需要排序的数组 A，它之中存在一个逆序，当数组中 i<j, 并且 A[i]>A[j]。例如对于上面的表格，存在 9 个逆序，分别是 (34, 8), (34, 32), (34, 21), (64, 32), (64, 21), (51, 32), (51, 21) 以及 (32, 21)。对于每次的相邻元素的交换，都仅仅消除一个逆序，而保证其他的逆序不发生变化。

>定理：对于 N 个互异数的数组的平均逆序数是 N(N-1)/4。

这条定理证明：如果一个数组逆序数为 N，将该数组从尾到头重新构造一个反序数组，其逆序数和 N 互补，和为总的元素两两组合的数量，即为 N(N-1)/2。所以平均逆序数为和的一半，也就是 N(N-1)/4。

而因此，我们在简单排序算法中，每次元素交换只能减少一个逆序，平均需要的时间就是 N(N-1)/4 = Ω(N^2) 时间。

所以根据我们理论推导，若是一个排序算法想要超过 N^2 的时间界，就必须每次交换超过一个逆序数，这就要求交换的两个对象尽可能远。

在代码中，我们使用到了如下的一个技巧：**在排序中避免使用交换**，交换是一个相对低效的方法，特别在连续相邻元素的交换中。我们可以先用一个临时变量储存起来需要插入的新值，然后从后向前比较与元素值的大小，若当前循环元素大于要插入的新值，则向后移一位，直到比较到小于新值的元素停止，并在该位置插入新值。

## 希尔排序(Shellsort)
希尔排序又被称为缩小增量排序，每次交换的元素之间存在一个距离。在第 k 次循环中，比较元素的间隔为 *hk*，我们保证对于任意 i，A[i]<=A[i+hk]，我们就称数组是 hk-排序的 (hk-sorted)。希尔排序的重要性质是，在接下来的循环中，尽管 h(k-1) 小于 hk，数组依旧能够保持 hk-排序的性质。

| 初始 | 81 | 94 | 11 | 96 | 12 | 35 | 17 | 95 | 28 |58 | 41 | 75 | 15 |
| :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: | :---: |
| 5-排序后 | 35 | 17 | 11 | 28 | 12 | 41 | 75 | 15 |96 | 58 | 81 | 94 | 95 | 
| 3-排序后 | 28 | 12 | 11 | 35 | 15 | 41 | 58 | 17 |94 | 75 | 81 | 96 | 95 | 
| 1-排序后 | 11 | 12 | 15 | 17 | 28 | 35 | 41 | 58 |75 | 81 | 94 | 95 | 96 |

希尔排序中对于 hk 的选择决定了其时间界的大小，而对于一个较为简单的选择，我们可以选择一开始的 h 为元素数量的一半，而每次循环的 hk 都是上一次的一半，实现的代码如下：

```c
void Shellsort(ElementType A[], int N) {
	int i, j, Increment;
	ElementType Tmp;

	for (Increment = N / 2; Increment > 0; Increment /= 2)
		for (i = Increment; i < N; i++) {
			Tmp = A[i];
			for (j = i; j >= Increment && A[j-Increment] > Tmp; j -= Increment)
					A[j] = A[j - Increment];
			A[j] = Tmp;
		}
}
```

这次依旧使用了之前插入排序中使用的 **避免交换** 的方法。代码类似于插入排序，只不过比较时加上了间隔 Increment 变量。每次 Increment 确定后，其实之后做的事情就是一个间隔 Increment 元素序列的插入排序。

### 如何选择 hk
想要更好地选择 hk 的值，可以使用 Hibbard 增量。Hibbard 增量的列为形如：1，3，7 ... 2^k-1 的序列，这些序列相邻之前没有公因子，而且有研究证明，使用 Hibbard 增量的最差情况运行时间为 *O(N^(3/2))*。证明这个时间常量需要使用到堆垒数论中某些众为所知的结果，我们不在这里详细描述。

## 堆排序
在先前的章节（[优先队列（堆）知识点](https://eggycat.coding.me/2018/07/24/Priority_Queue/)）中介绍了几种常见的堆模型，我们知道堆中的 DeleteMin 排序时间边界为 *O(N\*logN)*（每次为 logN，共 N 次），而构造堆的时间花费最坏情况为 *O(N)*。所以我们有总时间*O(N+N\*logN)*，也就是 *O(N\*logN)* 的时间边界，这样的边界是我们目前看到的最好的时间值，但是在实践中却低于 *Sedgewick* 增量序列的希尔排序。

但是使用二叉堆排序有一个问题，就是需要一个额外的数组用于构建二叉堆，这造成了空间上的花费。从排序后的二叉堆数组拷贝回原数组时时间为 *O(N)*，不会显著影响运行时间。

具体的实现过程就是先使用原数组的数据，构建一个二叉堆，在这个过程中，时间花费为 O(N)。然后逐步的 DeleteMax（之前二叉树是递增树，但是可以很简单的改成递减树），这个地方有一个小技巧，我们只用到二叉树的下滤操作，每次将二叉堆堆首元素与堆尾交换，然后对于堆头进行下滤操作，将二叉堆堆序性恢复，并且最大值被放置在了堆尾，缩减二叉堆的大小，我们就将最大值固定在了最后。逐步循环就得到了递增的排序。

```c
#define LeftChild(i) (2 * (i) + 1)
void PercDown(ElementType A[], int i, int N) {
	int Child;
	ElementType Tmp;

	for (Tmp = A[i]; LeftChild(i) < N; i = Child) {
		Child = LeftChild(i);
		if (Child != N - 1 && A[Child + 1] > A[Child])
			Child++;
		if (Tmp < A[Child])
			A[i] = A[Child];
		else
			break;
	}
	A[i] = Tmp;
}

void Heapsort(ElementType A[], int N) {
	int i;

	for (i = N / 2; i >= 0; i--) /* Build Heap Question: WHY i=N/2 */
		PercDown(A, i, N);
	for (i = N - 1; i > 0; i--) { /* DeleteMax */
		Swap(&A[0], &A[i]);
		PercDown(A, 0, i);
	}
}
```

#### 堆排序的分析
堆排序第一阶段最多用到 2N 次比较，第二阶段最多用到 2[logi] 次比较。堆排序是一个非常稳定的算法：它平均使用的比较和最坏情形接近，只是略少。直到最近，也没有人能够指出堆序排序平均运行时间的非平凡界。

## 归并排序
归并排序以 *O(N\*logN)* 最坏情形运行时间运行，但是比较的次数几乎是最优的。它是递归算法的一个很好的实例。

我们首先假设我们拥有了两个已经排序完成的表 A B，因为这两个表是已经排序完成的，若将其两个表合并成为一个排序的表 C 可以简单地通过一趟比较完成，对于一开始两个指针 Aptr 和 Bptr 被分别放在两个表的开头，然后比较指向的数据大小，较小的值会被放入 C，然后将较小值指针 +1，继续排序，当两个输入表有一个被用完的时候，则将另外一个表的剩余内容直接拷贝入 C。

![][1]

合并两个已排序表的时间是线性的，因为最多进行了 N-1 次比较，每次比较都至少添加进一个元素，而最后的那一次添加可以直接添加两个元素进去。

用递归表示归并排序：如果 N = 1，那么 A B 加起来就一个元素，直接将元素放置进 C 即可。否则，将前半部分和后半部分各自使用归并排序，并将结果使用合并算法合并。

归并排序的原理并不难，理解起来也较为容易，但是在递归的时候很容易就陷入 **尾递归** 的困境，我们下边的代码采用了一个共享的 `TmpArray` 数组，数据归并的过程中的过程数据都会暂时储存在这里，暂存数组的大小和原数组大小一致就可以，在迭代的过程中，所有的 Merge 都使用同一个暂存数组。这样我们迭代的过程中没有临时数组变量的产生，也就减少了内存的消耗，但是这样也造成了一个缺点，我们每次迭代的时候，Merge 函数都要输入这个暂存数组的指针，这个指针需要在不同的迭代次数之间传递。

```c
void MSort(ElementType A[], ElementType TmpArray[], int Left, int Right) {
	int Center;
	if (Left < Right) {
		Center = (Left + Right) / 2;
		MSort(A, TmpArray, Left, Center);
		MSort(A, TmpArray, Center + 1, Right);
		Merge(A, TmpArray, Left, Center + 1, Right);
	}
}

void Merge(ElementType A[], ElementType TmpArray[], int Lpos, int Rpos, int RightEnd) {
	int i, LeftEnd, NumElements, TmpPos;
	LeftEnd = Rpos - 1;
	TmpPos = Lpos;
	NumElements = RightEnd - Lpos + 1;

	/* Main Loop */
	while (Lpos <= LeftEnd&&Rpos <= RightEnd)
		if (A[Lpos] <= A[Rpos])
			TmpArray[TmpPos++] = A[Lpos++];
		else
			TmpArray[TmpPos++] = A[Rpos++];

	while (Lpos <= LeftEnd)
		TmpArray[TmpPos++] = A[Lpos++];
	while (RightEnd <= RightEnd)
		TmpArray[TmpPos++] = A[Rpos++];

	/* Copy back */
	for (i = 0; i < NumElements; i++, RightEnd--) {
		A[RightEnd] = Tmp[RightEnd];
	}
}
```

#### 归并排序的分析
通过分析归并排序，我们可以学习到分析递归程序的经典实例：我们必须根据运行的时间写出一个递归的关系。对于 N 个数归并的时间等于两个对半归并排序的时间加上复制的时间 O(N)。

下面是公式的显示，公式用了 MathJax 这个 JS 插件，如果你是手机浏览的，可以通过长按公式修改 Math Setting->Scale All Math 值缩放公式。


$$ T(1)=1 $$


$$ T(N)=2T(N/2)+N $$

我们将等式两边同时除以 N。

$$ \frac{T(N)}{N}=\frac{T(N/2)}{N/2}+1 $$

该等式对于任意 N 均成立，所以我们带入 N/2, N/4... ，并将它们左右式分别叠加。

$$ \frac{T(N)}{N} + \frac{T(N/2)}{N/2} + ... =\frac{T(N/2)}{N/2}+ 1 + \frac{T(N/4)}{N/4} + 1 +... $$

消去左右都有的项，我们可以得到：

$$ \frac{T(N)}{N}=\frac{T(1)}{1} + \log_2 N $$

化简可以得到 
$$T(N)=N\log_2N+N=O(N\log_{}N)$$

虽然归并排序的运行时间是 *O(NlogN)*，但是由于它需要一个和原本数据一样大的缓冲区作为数据暂存，所以在主存排序中很难应用。而且额外的拷贝操作也依赖于硬件的实现速度，在拷贝速度较慢的场合，将会大大拖慢排序速度。归并排序常常应用于外部排序当中，对于内部排序，人们还是会选择快速排序算法。

## 快速排序
快速排序是目前在实践中已知的最快的排序算法。它的平均运行时间是 *O(NlogN)*。该算法之所以特别快的原因是它具有非常精炼和高度优化的内部循环。

快速排序是采用了类似于归并排序类似的分治算法。原理是在集合中寻找一个枢纽元，然后将集合分为大于枢纽元的部分和小于枢纽元的部分。然后将两部分继续使用快速排序，直到最后的集合中有一个或者无元素，直接返回。

## 选取枢纽元
#### 一种错误的做法
一种想当然的做法是将输入的第一个元素用于枢纽元。这对于输入是随机的情况下是可用的，但是大部分情况下，对于预排序的输入，这种只会让快速排序每次运行在最坏的状态下。

#### 安全的做法
安全的做法是随机选取枢纽元。一般来说这种策略是非常有效的，除非随机数生成器产生了问题。但是随机数的产生是昂贵的，根本减少不了算法其余部分的平均运行时间。

事实上，完全随机的枢纽元的选择其实对于算法时间并没有什么帮助，因为最佳的选择是每一次都选中了正好能将数据分成两个数量相等的枢纽元，也就是集合的中值。但是选择中值的问题在于，我们无法获得中值位置，这需要大量的时间。所以我们采用了一种 **三数中值分割法** 的方法，我们从集合头，集合中部，集合尾各取一个元素，并且使用这三个元素的中间值作为枢纽元。

## 流程
#### 集合分割
在选取完枢纽元后，需要对于集合进行分割，重新整理成为两部分，这里的思路是先将集合中的枢纽元放在末尾，并且一个指针从头到尾滑过小于枢纽元的元素，一个指针从尾到头滑过大于枢纽元的元素，直到两个指针停下来，这时交换两个指针的元素，最后指针跨过另外一个指针，结束，将枢纽元从末尾和其中一个指针交换即可。

但是如果出现了等于枢纽元的元素，就要注意了，因为如果我们在此位置停下来，进行交换，其实是无意义的交换，但是这样有一个好处就是可以保证指针不会一次性滑过较多元素而导致两个最后划分的集合不均衡，所以我们的策略是遇到与枢纽元值相等的元素，依旧会停下指针，等待交换。

#### 小数组
在递归的过程中，会产生很多小的数组，对于很小的数组（N<20)，快速排序的效率甚至不如插入排序，这时因为快速排序采用了递归的方法。所以我们可以在快速排序中使用插入排序来处理小数组，而使用快速排序来处理大问题，这样不仅仅能够解决效率的问题，而且可以避免诸如三数中值分割法出现只有两个或一个元素的问题。

```c
ElementType Median3(ElementType A[], int Left, int Right) {
	int Center = (Left + Right) / 2;
	if (A[Left] > A[Center])
		Swap(&A[Left], &A[Center]);
	if (A[Left] > A[Right])
		Swap(&A[Left], &A[Right]);
	if (A[Center] > A[Right])
		Swap(&A[Center], &A[Right]);

	Swap(&A[Center], &A[Right - 1]);
	return A[Right - 1];
}

#define Cutoff(3)

void Qsort(ElementType A[], int Left, int Right) {
	int i, j;
	ElementType Pivot;

	if (Left + Cutoff <= Right) {
		Pivot = Median3(A, Left, Right);
		i = Left; j = Right - 1;
		for (;;) {
			while (A[++j] < Pivot) {}
			while (A[--j] > Pivot) {}
			if (i < j)
				Swap(&A[i], &A[j]);
			else
				break;
		}
		Swap(&A[i], &A[Right - 1]);

		Qsort(A, Left, i - 1);
		Qsort(A, i + 1, Right);
	}
	else
		InsertSort(A + Left, Right - Left + 1);
}
```

## 对于大型结构的排序
对于大型结构的排序，首先因为结构的性质使得复制的操作很难以进行，我们可以使用一个序列指针的方法，将指向结构的指针放置在一个数字中并对指针排序即可。这种排序被称作 **间接排序**。

## 桶式排序
桶式排序是一个很神奇的排序方法，因为他只需要线性的时间就可以对于数组进行排序。但是桶式排序的要求比较严格，被排序的元素必须是整数且是不大于 M 的，我们用另外一个大小为 M 初始化为 0 的数组，对于集合中任意一个元素，数组中都有一个下标与之对应，我们顺序记录元素在桶中不同位置的出现次数，譬如对于 3,8,2,4,5,1,3 序列使用一个 M=8 的数组，输入 3 则 M[3]++，输入 8，M[8]++。直到最后，按照值作为次数，打印出数组中的下标即可。桶式排序在较小的整数输入中效率很高。

为什么桶式排序能够打破 *O(NlogN)* 下界，其实很简单，因为桶式排序其实原理上使用的是一个 M-路选择器，和我们之前的两元比较不同，桶式排序一次性进行了 M 元比较，并最终确定了元素的位置。

## 外部排序
我们先前的排序，都是指内部排序，也就是集合储存在内存中，不考虑数据的读取和写入的时间消耗，但实际上，如果我们要将位于硬盘上的数据排序，或者位于磁盘上的数据进行排序，读取时间和写入时间会成为排序算法的瓶颈。

### 简单算法
简单的外部排序算法是使用归并排序中的 Merge 程序，我们需要用到两个磁带或者存储器件，设内存一次可以存储 M 个元素，我们就先从一个磁带中读取 M 个元素，使用内部排序将这些数据排序后，再把这些排过序的记录交替的写在两个磁盘上，这些排过序的记录叫做 **顺串**。当我们获得顺串之后，使用归并排序中的合并操作，将顺串成对合并即可。

### 多路合并
如果我们有好几个外部存储设备，这时候可以使用多路合并，也就是一次性对于多个顺串使用归并排序，将两路归并拓展到多路是很简单的，所以我们不做特别的描述。

## 总结
对于一般的内部排序应用，我们的选择只有三种，插入排序，希尔排序，快速排序，它们的选择主要是根据输入的规模决定的。归并排序的效率较低，但是它却是外部排序的关键思想。

[1]: /img/2018-7-27-Sorting/mergesort.png
