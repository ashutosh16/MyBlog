---
title: "Matrix Calculus"
date: 2020-01-30T20:17:54-05:00
draft: false
---

Matrix calculus is very important in machine learning and control theories. However there are all kinds of rules making it hard to remember and use. In this post, I summarize some basic rules and an important proof in machine learning theory, which includes the famous "Trace Trick"! This trick is super useful and super hard as well! Haha, this is the reason why we always explore new things, because it is hard!

<!--more-->

## Differetiate a matrix

Differentiating a matrix is same as differentiate all items in matrix respectively.

$$\\.{A}(t)=\begin{bmatrix}
\\.{A}_{11}(t) & \\cdots $ \\.{A}_{1n}(t) \cr
\\vdots & \\ddots & \\vdots \cr
\\.{A}_{n1}(t) & \\cdots & \\.A{nn}(t) \cr
\end{bmatrix}$$


